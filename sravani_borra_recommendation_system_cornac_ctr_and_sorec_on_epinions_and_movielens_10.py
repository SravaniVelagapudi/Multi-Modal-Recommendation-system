# -*- coding: utf-8 -*-
"""sravani-borra-recommendation-system-cornac-ctr-and-sorec-on-epinions-and-movielens-10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/gist/SravaniVelagapudi/b2c6a21f8949f261ddef07ae0c055a90/sravani-borra-recommendation-system-cornac-ctr-and-sorec-on-epinions-and-movielens-10.ipynb
"""

!pip install cornac

# Commented out IPython magic to ensure Python compatibility.
import cornac
from cornac.data import TextModality, GraphModality
from cornac.eval_methods import RatioSplit, CrossValidation
from cornac.experiment import Experiment
from cornac import metrics
from cornac.models import SoRec, PMF, CTR, WMF
from cornac.models import SoRec, PMF
from cornac.data import Reader
from cornac.data.text import BaseTokenizer

from scipy.io import loadmat
import pandas as pd
from itertools import product

import itertools
import os
import sys
from collections import defaultdict

# %tensorflow_version 1.x
import tensorflow as tf

from scipy import stats
import numpy as np

import random

from tqdm.auto import tqdm
tqdm.pandas()

import matplotlib.pyplot as plt
import seaborn as sns

import warnings
warnings.filterwarnings('ignore')

SEED = 42
VERBOSE = True

!apt install msttcorefonts -qq
!rm ~/.cache/matplotlib -rf

"""## Social Recommendation using PMF (SoRec)

SoRec leverages social relationships among users (e.g., trust), it jointly factorizes the user-item and user-user matrices
"""

# !wget -q --show-progress https://snap.stanford.edu/data/soc-Epinions1.txt.gz
# !gunzip soc-Epinions1.txt.gz
# https://www.cse.msu.edu/~tangjili/datasetcode/truststudy.htm
# https://github.com/JiaWu-Repository/STNE/blob/master/input/Epinions.txt
# http://www.trustlet.org/extended_epinions.html
# http://www.trustlet.org/downloaded_epinions.html
# https://github.com/parthpatel002/Social_Collaborative_Filtering_by_Trust/tree/master/data
# https://www.cse.msu.edu/~tangjili/trust.html

!wget -q --show-progress http://www.cse.msu.edu/~tangjili/datasetcode/epinions.zip
!unzip epinions.zip
!wget -q --show-progress http://www.cse.msu.edu/~tangjili/datasetcode/catalog_epinion.txt

epinions_rating = loadmat('epinions/rating.mat')['rating']
epinions_rating

epinions_rating = pd.DataFrame(epinions_rating,
                               columns=['userid', 'productid', 'categoryid', 'rating'])
epinions_rating = epinions_rating.astype('str')
epinions_rating = epinions_rating[['userid', 'productid', 'rating']]
epinions_rating.head()

epinions_rating.describe()

density = len(epinions_rating) / (epinions_rating.userid.nunique() * epinions_rating.productid.nunique())
sparsity = 1 - density
print('Sparsity of the data is {:.4%}'.format(sparsity))

def remove_cat_outliers(df, col, sd=3):
    x = df[col].value_counts()
    valid_ids = list(set(x[(np.abs(stats.zscore(x)) < sd)].index.tolist()))
    valid_ids = [str(x) for x in valid_ids]
    df = df[df[col].isin(valid_ids)]
    return df

epinions_rating = remove_cat_outliers(epinions_rating, col='userid')
epinions_rating = remove_cat_outliers(epinions_rating, col='productid')
epinions_rating.describe()

"""The code in the below cell is for data sampling. Here, we are randomly picking only few users so that multiple models can be trained faster. For full data training, comment/skip this code."""

random_user_ids = random.sample(list(epinions_rating['userid'].unique()), 1000)
epinions_rating = epinions_rating[epinions_rating['userid'].isin(random_user_ids)]
epinions_rating.describe()

density = len(epinions_rating) / (epinions_rating.userid.nunique() * epinions_rating.productid.nunique())
sparsity = 1 - density
print('Sparsity of the data is {:.4%}'.format(sparsity))

epinions_rating_data = [tuple(x) for x in epinions_rating.to_numpy()]
epinions_rating_data[:5]

epinions_trust = loadmat('epinions/trustnetwork.mat')['trustnetwork']
epinions_trust

epinions_trust = pd.DataFrame(epinions_trust,
                               columns=['user1', 'user2'])
epinions_trust['weight'] = 1
epinions_trust = epinions_trust.astype('str')
epinions_trust.head()

epinions_trust.describe()

epinions_trust = epinions_trust[epinions_trust['user1'].isin(epinions_rating.userid.unique())]
epinions_trust = epinions_trust[epinions_trust['user2'].isin(epinions_rating.userid.unique())]
epinions_trust.describe()

epinions_trust_data = [tuple(x) for x in epinions_trust.to_numpy()]
epinions_trust_data[:5]

# Instantiate a GraphModality, it makes it convenient to work with graph (network) auxiliary information
user_graph_modality = GraphModality(data=epinions_trust_data)

# Define an evaluation method to split feedback into train and test sets
eval_method = CrossValidation(
    data=epinions_rating_data,
    n_folds=5,
    rating_threshold=2.5,
    exclude_unknowns=True,
    verbose=True,
    user_graph=user_graph_modality,
    seed=123,
)

# Instantiate SoRec model
K = 20
sorec = SoRec(k=K, max_iter=50, learning_rate=0.001, verbose=VERBOSE, seed=SEED)
pmf = PMF(k=K, max_iter=50, learning_rate=0.001, lambda_reg=0.01, verbose=VERBOSE, seed=SEED)

# Evaluation metrics
rmse = metrics.RMSE()
mae = metrics.MAE()

# Put everything together into an experiment and run it
Experiment(
    eval_method=eval_method, models=[sorec, pmf], metrics=[rmse, mae]
).run()

# Instantiate a GraphModality, it makes it convenient to work with graph (network) auxiliary information
user_graph_modality = GraphModality(data=epinions_trust_data)

# Define an evaluation method to split feedback into train and test sets
ratio_split = RatioSplit(
    data=epinions_rating_data,
    test_size=0.2,
    rating_threshold=2.5,
    exclude_unknowns=True,
    verbose=True,
    user_graph=user_graph_modality,
    seed=123,
)

# Instantiate SoRec model
K = 20
sorec = SoRec(k=K, max_iter=50, learning_rate=0.001, verbose=VERBOSE, seed=SEED)
pmf = PMF(k=K, max_iter=50, learning_rate=0.001, lambda_reg=0.01, verbose=VERBOSE, seed=SEED)

# Evaluation metrics
rmse = metrics.RMSE()
mae = metrics.MAE()

# Put everything together into an experiment and run it
Experiment(
    eval_method=ratio_split, models=[sorec, pmf], metrics=[rmse, mae]
).run()

sorec.U

"""Below is the variance of each user latent dimension."""

# variance of each user latent dimension

var_df = pd.DataFrame({"Factor": np.arange(K), "Variance": np.var(sorec.U, axis=0)})
fig, ax = plt.subplots(figsize=(13, 5))
sns.barplot(x="Factor", y="Variance", data=var_df, palette="ch:.25", ax=ax);

"""Let's select two dimensions and see how users are distributed in that 2D space. In addition, we can visualize connections between two users if they are linked in the social network."""

TOP2F = (2, 7)
SAMPLE_SIZE = 200

rng = np.random.RandomState(SEED)
sample_inds = rng.choice(np.arange(sorec.U.shape[0]), size=SAMPLE_SIZE, replace=False)
sample_df = pd.DataFrame(data=sorec.U[sample_inds][:, TOP2F], columns=["x", "y"])

g = sns.lmplot(x="x", y="y", data=sample_df, height=8.0, fit_reg=False)
g.ax.set_title("Users in latent space with their social connections", fontsize=16)

adj_mat = sorec.train_set.user_graph.matrix
for i in range(len(sample_inds)):
  for j in range(len(sample_inds)):
    if j != i and adj_mat[sample_inds[i], sample_inds[j]]:
      sns.lineplot(x="x", y="y", data=sample_df.loc[[i, j]])

"""There are indeed some locality of user connections shown in the figure above. That suggests social network information is captured in the user latent factors and has some influence on the recommendations by the SoRec model.

### Grid
"""

class CustomExperiment(Experiment):
    def run(self):
        """Run the Cornac experiment"""
        self._create_result()

        for model in self.models:
            test_result, val_result = self.eval_method.evaluate(
                model=model,
                metrics=self.metrics,
                user_based=self.user_based,
                show_validation=self.show_validation,
            )

            self.result.append(test_result)

def experiment(row,
               epinions_rating=None,
               epinions_trust=None):
    
    VERBOSE = False
    test_size = row.test_size
    K = row.K
    rating_threshold = row.rating_threshold
    learning_rate = row.learning_rate
    lambda_reg = row.lambda_reg
    lambda_c = row.lambda_c
    user_based = row.user_based
    model = row.model
    # sample_size = row.sample_size

    # if sample_size is not None:
    #     epinions_rating = epinions_rating.sample(n=int(sample_size))
    #     epinions_trust = epinions_trust[epinions_trust['user1'].isin(epinions_rating.userid.unique())]
    #     epinions_trust = epinions_trust[epinions_trust['user2'].isin(epinions_rating.userid.unique())]
    
    # epinions_rating_data = [tuple(x) for x in epinions_rating.to_numpy()]
    # epinions_trust_data = [tuple(x) for x in epinions_trust.to_numpy()]
    
    # user_graph_modality = GraphModality(data=epinions_trust_data)

    # Define an evaluation method to split feedback into train and test sets
    ratio_split = RatioSplit(
        data=epinions_rating_data,
        test_size=test_size,
        rating_threshold=rating_threshold,
        exclude_unknowns=True,
        verbose=VERBOSE,
        user_graph=user_graph_modality,
        seed=SEED
    )

    if model == 'sorec':
        model = SoRec(k=K, max_iter=50, learning_rate=learning_rate, lambda_c=lambda_c, verbose=VERBOSE, seed=SEED)
    elif model == 'pmf':
        model = PMF(k=K, max_iter=50, learning_rate=learning_rate, lambda_reg=lambda_reg, verbose=VERBOSE, seed=SEED)

    exp = CustomExperiment(eval_method=ratio_split, models=[model], metrics=[mae], user_based=user_based,
                     verbose=VERBOSE, save_dir=None)
    _ = exp.run()

    row = row.append(pd.Series(dict(exp.result[0].metric_avg_results)))

    return row

sns.set()
sns.set_style("whitegrid", {'axes.grid' : False})
sns.set_style("ticks", {'axes.grid' : False})

rc = {'figure.figsize':(10, 5),
      'axes.facecolor':'white',
      'axes.grid' : True,
      'grid.color': '1',
      'font.family':'Times New Roman',
      'font.size' : 15}
plt.rcParams.update(rc)

"""### Exp 1"""

# grid
# test_size = [0.01, 0.2, 0.5, 0.8]
# K = [5, 10]
# rating_threshold = [2.5]
# learning_rate = [0.001]
# lambda_reg = [0.01]
# lambda_c = [5,10,15,20,50,100]
# sample_size = [None] # takes full data if none
# user_based = [True]
# model = ['sorec','pmf']

test_size = [0.01, 0.2, 0.5, 0.8]
K = [20]
rating_threshold = [2.5]
learning_rate = [0.001]
lambda_reg = [0.01]
lambda_c = [5,10,15,20,50,100]
sample_size = [None] # takes full data if none
user_based = [True]
model = ['sorec']

params = pd.DataFrame(list(product(test_size, K, rating_threshold,
                          learning_rate, lambda_reg, lambda_c,
                          user_based, model, sample_size)),
                        columns=['test_size', 'K',
                                'rating_threshold',
                                'learning_rate',
                                'lambda_reg',
                                 'lambda_c',
                                 'user_based',
                                 'model',
                                 'sample_size'])

params

results1 = params.progress_apply(experiment, axis=1)

results1.head()

data = results1[['test_size', 'lambda_c', 'MAE']]
data['test_size'] = data.apply(lambda row: 'SoRec {:.0%} as Testing data'.format(row.test_size), axis=1)
data = data.rename(columns={'test_size':'Model & Testing size'})
data

g = sns.relplot(data=data, x='lambda_c', y='MAE',
                hue='Model & Testing size', style='Model & Testing size',
                markers=True, dashes=False,
                kind='line')
g.set(xlabel = "Values of $\lambda_C$", ylabel = "MAE")
sns.despine(fig=None, ax=None, top=False, right=False, left=False, bottom=False, offset=None, trim=False)
plt.show()

g.figure.savefig('SoRec_1_v2.svg', format='svg', dpi=1200)

"""### Exp 2"""

test_size = [0.01, 0.2, 0.5, 0.8]
K = [5, 10, 20, 30, 50, 100]
rating_threshold = [2.5]
learning_rate = [0.001]
lambda_reg = [0.01]
lambda_c = [10]
sample_size = [None] # takes full data if none
user_based = [True]
model = ['sorec','pmf']

params = pd.DataFrame(list(product(test_size, K, rating_threshold,
                          learning_rate, lambda_reg, lambda_c,
                          user_based, model, sample_size)),
                        columns=['test_size', 'K',
                                'rating_threshold',
                                'learning_rate',
                                'lambda_reg',
                                 'lambda_c',
                                 'user_based',
                                 'model',
                                 'sample_size'])

params

results2 = params.progress_apply(experiment, axis=1)

results2.head()

data = results2[['test_size', 'K', 'model', 'MAE']]
data['model'] = data['model'].replace({'sorec':'SoRec', 'pmf':'PMF'})
data['model_k'] = data.apply(lambda row: '{} @ K={}'.format(row.model, row.K), axis=1)
data.drop(['model','K'], axis=1, inplace=True)
data = data.rename(columns={'model_k':'Model & Dimensionality',
                            'test_size':'Testing Data'})
data

g = sns.relplot(data=data, x='Testing Data', y='MAE',
                hue='Model & Dimensionality', style='Model & Dimensionality',
                markers=True, dashes=False,
                kind='line')
g.set(xlabel = "Testing Data", ylabel = "MAE")
sns.despine(fig=None, ax=None, top=False, right=False, left=False, bottom=False, offset=None, trim=False)
plt.show()

g.figure.savefig('SoRec_2_v2.svg', format='svg', dpi=1200)

"""## CTR (Collaborative Topic regression)

CTR composes the LDA topic model with matrix factorization to model item (article) texts and user-item preferences
"""

!cp /content/drive/MyDrive/TempData/srivani_b_recsys/*.svg /content/
!cp /content/drive/MyDrive/TempData/srivani_b_recsys/*.csv /content/

from tqdm.auto import tqdm
tqdm.pandas()

movie_df = pd.read_csv('movie_df.csv')
movie_df.head()

# convert to list
docs = movie_df.text.tolist()
item_ids = [str(x) for x in movie_df.movie_id.tolist()]

rating = pd.read_csv('rating.csv')
rating.head()

feedback = [tuple(x) for x in rating.to_numpy()]
feedback[:5]

len(docs), len(item_ids), len(feedback)

docs[:5]

item_ids[:5]

feedback[:5]

id_encode_map = {k:str(v) for v,k in enumerate(set(item_ids))}

id_encode_map['4']

id_encode_map['7']

item_ids = [id_encode_map[x] for x in item_ids]
item_ids[:5]

feedback = [(x[0], id_encode_map[x[1]], x[2]) for x in feedback]
feedback[:5]

# Instantiate a TextModality, it makes it convenient to work with text auxiliary information
item_text_modality = TextModality(
    corpus=docs,
    ids=item_ids,
    tokenizer=BaseTokenizer(sep=" ", stop_words="english"),
    max_vocab=3000,
    max_doc_freq=0.7,
)

# Define an evaluation method to split feedback into train and test sets
eval_method = CrossValidation(
    data=feedback,
    n_folds=5,
    exclude_unknowns=True,
    item_text=item_text_modality,
    verbose=True,
    seed=123,
    rating_threshold=3,
)

K = 20
ctr = CTR(k=K, max_iter=50, a=1.0, b=0.01, lambda_u=0.01, lambda_v=0.01, verbose=VERBOSE, seed=SEED)
wmf = WMF(k=K, max_iter=50, a=1.0, b=0.01, learning_rate=0.005, lambda_u=0.01, lambda_v=0.01, 
          verbose=VERBOSE, seed=SEED)

# Use Recall@100 for evaluation
rec_100 = cornac.metrics.Recall(k=100)

# Put everything together into an experiment and run it
cornac.Experiment(eval_method=eval_method, models=[wmf, ctr], metrics=[rec_100]).run()

# Instantiate a TextModality, it makes it convenient to work with text auxiliary information
item_text_modality = TextModality(
    corpus=docs,
    ids=item_ids,
    tokenizer=BaseTokenizer(sep=" ", stop_words="english"),
    max_vocab=3000,
    max_doc_freq=0.8,
)

# Define an evaluation method to split feedback into train and test sets
eval_method = RatioSplit(
    data=feedback,
    test_size=0.2,
    exclude_unknowns=True,
    item_text=item_text_modality,
    verbose=True,
    seed=123,
    rating_threshold=3,
)

K = 20
ctr = CTR(k=K, max_iter=50, a=1.0, b=0.01, lambda_u=0.01, lambda_v=0.01, verbose=VERBOSE, seed=SEED)
wmf = WMF(k=K, max_iter=50, a=1.0, b=0.01, learning_rate=0.005, lambda_u=0.01, lambda_v=0.01, 
          verbose=VERBOSE, seed=SEED)

# Use Recall@100 for evaluation
rec_100 = cornac.metrics.Recall(k=100)

# Put everything together into an experiment and run it
cornac.Experiment(eval_method=eval_method, models=[wmf, ctr], metrics=[rec_100]).run()

"""As CTR is based on topic model, it has intuitive explainability both in terms of model parameters as well as its recommendations. First, we can see what the top words of each topic are, based on learned topic-word distributions :"""

vocab = ctr.train_set.item_text.vocab
topic_word_dist = ctr.model.beta.T[:, -ctr.train_set.item_text.max_vocab:] 
top_word_inds = np.argsort(topic_word_dist, axis=1) + 4  # ingore 4 special tokens

topic_words = {}
topic_df = defaultdict(list)
print("WORD TOPICS:")
for t in range(len(topic_word_dist)):
  top_words = vocab.to_text(top_word_inds[t][-10:][::-1], sep=", ")
  topic_words[t+1] = top_words
  topic_df["Topic"].append(t + 1)
  topic_df["Top words"].append(top_words)
topic_df = pd.DataFrame(topic_df)
topic_df

"""As item vectors are close to its topic proportions, user vectors can also be used to explain what topics they are interested in."""

UIDX = 23
TOPK = 5

item_id2idx = ctr.train_set.iid_map
item_idx2id = list(ctr.train_set.item_ids)

print(f"USER {UIDX} TOP-3 TOPICS:")
topic_df.loc[np.argsort(ctr.U[UIDX])[-3:][::-1]]

"""Those are the topics most relevant to user interests. What will be recommendations to this user?"""

recommendations, scores = ctr.rank(UIDX)
print(f"\nTOP {TOPK} RECOMMENDATIONS FOR USER {UIDX}:")
rec_df = defaultdict(list)
for i in recommendations[:TOPK]:
  rec_df["Description"].append(ctr.train_set.item_text.corpus[i])
pd.DataFrame(rec_df)

"""Let's check out another user with index = 321. Similarly, we see the top-3 topics this user cares most about:"""

UIDX = 4

print(f"USER {UIDX} TOP-3 TOPICS:")
topic_df.loc[np.argsort(ctr.U[UIDX])[-3:][::-1]]

"""Based on this, how would the model give recommendations to the user?"""

recommendations, scores = ctr.rank(UIDX)
print(f"\nTOP {TOPK} RECOMMENDATIONS FOR USER {UIDX}:")
rec_df = defaultdict(list)
for i in recommendations[:TOPK]:
  rec_df["Description"].append(ctr.train_set.item_text.corpus[i])
pd.DataFrame(rec_df)

class CustomExperiment(Experiment):
    def run(self):
        """Run the Cornac experiment"""
        self._create_result()

        for model in self.models:
            test_result, val_result = self.eval_method.evaluate(
                model=model,
                metrics=self.metrics,
                user_based=self.user_based,
                show_validation=self.show_validation,
            )

            self.result.append(test_result)

sns.set()
sns.set_style("whitegrid", {'axes.grid' : False})
sns.set_style("ticks", {'axes.grid' : False})

rc = {'figure.figsize':(10, 5),
      'axes.facecolor':'white',
      'axes.grid' : True,
      'grid.color': '1',
      'font.family':'Times New Roman',
      'font.size' : 15}
plt.rcParams.update(rc)

def experiment(row, feedback=None):
    
    VERBOSE = False
    test_size = row.test_size
    K = row.K
    rating_threshold = row.rating_threshold
    learning_rate = row.learning_rate
    user_based = row.user_based
    model = row.model
    lambda_u = row.lambda_u
    lambda_v = row.lambda_v
    sample_size = row.sample_size
    feedback = random.sample(feedback, int(len(feedback)*sample_size))

    # Instantiate a TextModality, it makes it convenient to work with text auxiliary information
    item_text_modality = TextModality(
        corpus=docs,
        ids=item_ids,
        tokenizer=BaseTokenizer(sep=" ", stop_words="english"),
        max_vocab=3000,
        max_doc_freq=0.8,
    )

    # Use Recall@100 for evaluation
    rec_100 = cornac.metrics.Recall(k=100)

    ratio_split = RatioSplit(
        data=feedback,
        test_size=test_size,
        exclude_unknowns=True,
        item_text=item_text_modality,
        verbose=VERBOSE,
        seed=SEED,
        rating_threshold=rating_threshold,
    )

    if model == 'ctr':
        model = CTR(k=K, max_iter=50, a=1.0, b=0.01, lambda_u=lambda_u, lambda_v=lambda_v, verbose=VERBOSE, seed=SEED)
    elif model == 'wmf':
        model = WMF(k=K, max_iter=50, a=1.0, b=0.01, learning_rate=learning_rate, lambda_u=lambda_u, lambda_v=lambda_v, verbose=VERBOSE, seed=SEED)

    exp = CustomExperiment(eval_method=ratio_split, models=[model], metrics=[rec_100], user_based=user_based,
                     verbose=VERBOSE, save_dir=None)
    _ = exp.run()

    # return exp

    row = row.append(pd.Series(dict(exp.result[0].metric_avg_results)))

    return row

"""### Exp 1"""

# grid
test_size = [0.2]
K = [20]
rating_threshold = [3]
learning_rate = [0.001]
lambda_u = [0.01]
lambda_v = [0.01]
sample_size = [1, 0.8, 0.5, 0.2, 0.1]
user_based = [True]
model = ['ctr','wmf']

params = pd.DataFrame(list(product(test_size, K, rating_threshold,
                          learning_rate, lambda_u, lambda_v,
                          user_based, model, sample_size)),
                        columns=['test_size', 'K',
                                'rating_threshold',
                                'learning_rate',
                                'lambda_u',
                                'lambda_v',
                                 'user_based',
                                 'model',
                                 'sample_size'])

params

results1 = params.progress_apply(experiment, feedback=feedback, axis=1)
results1.head()

data = results1[['sample_size', 'model', 'Recall@100']]
data['model'] = data['model'].replace({'ctr':'CTR', 'wmf':'WMF'})
data = data.rename(columns={'model':'Model', 'sample_size':'Training size'})
data

g = sns.relplot(data=data, x='Training size', y='Recall@100',
                hue='Model', style='Model',
                markers=True, dashes=False,
                kind='line')
g.set(xlabel = "Training size", ylabel = "Recall@100")
sns.despine(fig=None, ax=None, top=False, right=False, left=False, bottom=False, offset=None, trim=False)
plt.show()

g.figure.savefig('CTR_3_v2.svg', format='svg', dpi=1200)

g = sns.barplot(data=data, x='Training size', y='Recall@100', hue='Model')
plt.show()

g.figure.savefig('CTR_3_v2_bar.svg', format='svg', dpi=1200)

"""### Exp 2"""

test_size = [0.2]
K = [10, 20, 40, 60, 100, 150, 200]
rating_threshold = [3]
learning_rate = [0.001]
lambda_u = [0.01]
lambda_v = [0.01]
sample_size = [1]
user_based = [True]
model = ['ctr','wmf']

params = pd.DataFrame(list(product(test_size, K, rating_threshold,
                          learning_rate, lambda_u, lambda_v,
                          user_based, model, sample_size)),
                        columns=['test_size', 'K',
                                'rating_threshold',
                                'learning_rate',
                                'lambda_u',
                                'lambda_v',
                                 'user_based',
                                 'model',
                                 'sample_size'])

params

results2 = params.progress_apply(experiment, feedback=feedback, axis=1)
results2.head()

data = results2[['K', 'model', 'Recall@100']]
data['model'] = data['model'].replace({'ctr':'CTR', 'wmf':'WMF'})
data = data.rename(columns={'model':'Model',
                            'K':'Dimensionality'})
data

g = sns.relplot(data=data, x='Dimensionality', y='Recall@100',
                hue='Model', style='Model',
                markers=True, dashes=False,
                kind='line')
g.set(xlabel = "Dimensionality ($K$)", ylabel = "Recall@100")
sns.despine(fig=None, ax=None, top=False, right=False, left=False, bottom=False, offset=None, trim=False)
plt.show()

g.figure.savefig('CTR_2_v3.svg', format='svg', dpi=1200)

g = sns.barplot(data=data, x='Dimensionality', y='Recall@100', hue='Model')
plt.show()

g.figure.savefig('CTR_2_v3_bar.svg', format='svg', dpi=1200)

"""### Exp3"""

test_size = [0.2]
K = [20]
rating_threshold = [3]
learning_rate = [0.001]
lambda_u = [0.01, 0.1, 0.03, 0.5, 1]
lambda_v = [0.01]
sample_size = [1]
user_based = [True]
model = ['ctr','wmf']


params = pd.DataFrame(list(product(test_size, K, rating_threshold,
                          learning_rate, lambda_u, lambda_v,
                          user_based, model, sample_size)),
                        columns=['test_size', 'K',
                                'rating_threshold',
                                'learning_rate',
                                'lambda_u',
                                'lambda_v',
                                 'user_based',
                                 'model',
                                 'sample_size'])

params

results3 = params.progress_apply(experiment, feedback=feedback, axis=1)
results3.head()

data = results3[['lambda_u', 'model', 'Recall@100']]
data['model'] = data['model'].replace({'ctr':'CTR', 'wmf':'WMF'})
data = data.rename(columns={'model':'Model'})
data

g = sns.relplot(data=data, x='lambda_u', y='Recall@100',
                hue='Model', style='Model',
                markers=True, dashes=False,
                kind='line')
g.set(xlabel = "$\lambda_u$", ylabel = "Recall@100")
sns.despine(fig=None, ax=None, top=False, right=False, left=False, bottom=False, offset=None, trim=False)
plt.show()

g.figure.savefig('CTR_3_v3.svg', format='svg', dpi=1200, bbox_inches="tight")

g = sns.barplot(data=data, x='lambda_u', y='Recall@100', hue='Model')
g.set(xlabel = "$\lambda_u$")
plt.show()

g.figure.savefig('CTR_3_v3_bar.svg', format='svg', dpi=1200)

"""### Exp4"""

test_size = [0.2]
K = [20]
rating_threshold = [3]
learning_rate = [0.001]
lambda_u = [0.01]
lambda_v = [0.01, 0.1, 0.03, 0.5, 1]
sample_size = [1]
user_based = [True]
model = ['ctr','wmf']

params = pd.DataFrame(list(product(test_size, K, rating_threshold,
                          learning_rate, lambda_u, lambda_v,
                          user_based, model, sample_size)),
                        columns=['test_size', 'K',
                                'rating_threshold',
                                'learning_rate',
                                'lambda_u',
                                'lambda_v',
                                 'user_based',
                                 'model',
                                 'sample_size'])

params

results4 = params.progress_apply(experiment, feedback=feedback, axis=1)
results4.head()

data = results4[['lambda_v', 'model', 'Recall@100']]
data['model'] = data['model'].replace({'ctr':'CTR', 'wmf':'WMF'})
data = data.rename(columns={'model':'Model'})
data

g = sns.relplot(data=data, x='lambda_v', y='Recall@100',
                hue='Model', style='Model',
                markers=True, dashes=False,
                kind='line')
g.set(xlabel = "$\lambda_v$", ylabel = "Recall@100")
sns.despine(fig=None, ax=None, top=False, right=False, left=False, bottom=False, offset=None, trim=False)
plt.show()

g.figure.savefig('CTR_4_v3.svg', format='svg', dpi=1200, bbox_inches="tight")

g = sns.barplot(data=data, x='lambda_v', y='Recall@100', hue='Model')
g.set(xlabel = "$\lambda_v$")
plt.show()

g.figure.savefig('CTR_4_v3_bar.svg', format='svg', dpi=1200)

"""### Exp5"""

test_size = [0.2]
K = [20]
rating_threshold = [3]
learning_rate = [0.001]
lambda_u = [0.01]
lambda_v = [0.01, 1, 10, 100, 1000]
sample_size = [1]
user_based = [True]
model = ['ctr','wmf']

params = pd.DataFrame(list(product(test_size, K, rating_threshold,
                          learning_rate, lambda_u, lambda_v,
                          user_based, model, sample_size)),
                        columns=['test_size', 'K',
                                'rating_threshold',
                                'learning_rate',
                                'lambda_u',
                                'lambda_v',
                                 'user_based',
                                 'model',
                                 'sample_size'])

params

results5 = params.progress_apply(experiment, feedback=feedback, axis=1)
results5.head()

data = results5[['lambda_v', 'model', 'Recall@100']]
data['model'] = data['model'].replace({'ctr':'CTR', 'wmf':'WMF'})
data = data.rename(columns={'model':'Model'})
data

g = sns.relplot(data=data, x='lambda_v', y='Recall@100',
                hue='Model', style='Model',
                markers=True, dashes=False,
                kind='line')
g.set(xlabel = "$\lambda_v$", ylabel = "Recall@100")
sns.despine(fig=None, ax=None, top=False, right=False, left=False, bottom=False, offset=None, trim=False)
plt.show()

g.figure.savefig('CTR_5_v3.svg', format='svg', dpi=1200, bbox_inches="tight")

g = sns.barplot(data=data, x='lambda_v', y='Recall@100', hue='Model')
g.set(xlabel = "$\lambda_v$")
plt.show()

g.figure.savefig('CTR_5_v3_bar.svg', format='svg', dpi=1200)

"""---"""

!cp /content/*.svg /content/drive/MyDrive/TempData/srivani_b_recsys
!cp /content/*.csv /content/drive/MyDrive/TempData/srivani_b_recsys

"""*End*"""